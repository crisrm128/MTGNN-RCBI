{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "WWVKGT9Vy0wR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG-NfuJiro9z",
        "outputId": "f26efee3-349e-43d2-93b2-e551534267e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MTGNN-RCBI' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/crisrm128/MTGNN-RCBI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MTGNN-RCBI/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmmlXLX8r2SO",
        "outputId": "5e9493f1-a534-4335-f9a2-1166280171d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTGNN-RCBI/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip traffic_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_VCFXGJyzks",
        "outputId": "44e7afcf-1341-497e-db76-9edc7ca3ed69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  traffic_dataset.zip\n",
            "replace metr-la.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace pems-bay.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip multivariate_timeseries_datasets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uflib9A2ssA",
        "outputId": "54ea1f19-5895-4d33-e438-042d81a67a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  multivariate_timeseries_datasets.zip\n",
            "replace electricity.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace exchange_rate.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace solar_AL.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace traffic.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {METR-LA,PEMS-BAY}"
      ],
      "metadata": {
        "id": "y-maFJBczH8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux-lLR89zs0m",
        "outputId": "5d68f31b-6cfc-4aa6-d70c-a5af55563cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTGNN-RCBI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_training_data.py --output_dir=data/METR-LA --traffic_df_filename=data/metr-la.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3_vkdfQzS_n",
        "outputId": "9dd30d08-4b0a-4bb6-c652-0af1d5b554ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data\n",
            "n\n",
            "x shape:  (34249, 12, 207, 2) , y shape:  (34249, 12, 207, 2)\n",
            "train x:  (23974, 12, 207, 2) y: (23974, 12, 207, 2)\n",
            "val x:  (3425, 12, 207, 2) y: (3425, 12, 207, 2)\n",
            "test x:  (6850, 12, 207, 2) y: (6850, 12, 207, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "⚠️ It doesn't work well, as I don't know the reason why de \"^C\" appears without pressing any keys.\n",
        "\n",
        "It doesn't matter anyway, because this problem is associated with a traffic dataset, which is irrelevant in this project.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bazLb6R-2Ere"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_training_data.py --output_dir=data/PEMS-BAY --traffic_df_filename=data/pems-bay.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aQpor6hzUpV",
        "outputId": "8e16b923-465d-41dc-cf1a-6177af42412e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "GR9OVBC3zXuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "python train_single_step.py --save ./model-electricity-3.pt --data ./data/electricity.txt --num_nodes 321 --batch_size 4 --epochs 3 --horizon 3 --device 'cuda:0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YkxCFUDLr5QB",
        "outputId": "583b63e3-b556-4bd6-e180-6c20b85e67d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "begin training\n",
            "iter:  0 | loss: 3808.924\n",
            "iter:100 | loss: 391.339\n",
            "iter:200 | loss: 417.622\n",
            "iter:300 | loss: 285.247\n",
            "iter:400 | loss: 365.934\n",
            "iter:500 | loss: 198.703\n",
            "iter:600 | loss: 235.693\n",
            "iter:700 | loss: 207.395\n",
            "iter:800 | loss: 208.073\n",
            "iter:900 | loss: 179.544\n",
            "iter:1000 | loss: 320.885\n",
            "iter:1100 | loss: 297.938\n",
            "iter:1200 | loss: 262.602\n",
            "iter:1300 | loss: 324.903\n",
            "iter:1400 | loss: 219.595\n",
            "iter:1500 | loss: 216.121\n",
            "iter:1600 | loss: 249.960\n",
            "iter:1700 | loss: 168.982\n",
            "iter:1800 | loss: 167.825\n",
            "iter:1900 | loss: 223.858\n",
            "iter:2000 | loss: 255.288\n",
            "iter:2100 | loss: 331.749\n",
            "iter:2200 | loss: 247.263\n",
            "iter:2300 | loss: 166.684\n",
            "iter:2400 | loss: 163.414\n",
            "iter:2500 | loss: 174.747\n",
            "iter:2600 | loss: 204.256\n",
            "iter:2700 | loss: 192.540\n",
            "iter:2800 | loss: 269.018\n",
            "iter:2900 | loss: 222.555\n",
            "iter:3000 | loss: 134.673\n",
            "iter:3100 | loss: 184.270\n",
            "iter:3200 | loss: 196.590\n",
            "iter:3300 | loss: 191.896\n",
            "iter:3400 | loss: 177.738\n",
            "iter:3500 | loss: 208.692\n",
            "iter:3600 | loss: 211.202\n",
            "iter:3700 | loss: 149.235\n",
            "iter:3800 | loss: 190.193\n",
            "iter:3900 | loss: 174.467\n",
            "/content/MTGNN-RCBI/train_single_step.py:53: RuntimeWarning: invalid value encountered in divide\n",
            "  correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis=0) / (sigma_p * sigma_g)\n",
            "| end of epoch   1 | time: 698.58s | train_loss 240.0995 | valid rse 0.0591 | valid rae 0.0431 | valid corr  0.9209\n",
            "iter:  0 | loss: 147.326\n",
            "iter:100 | loss: 237.632\n",
            "iter:200 | loss: 151.823\n",
            "iter:300 | loss: 167.800\n",
            "iter:400 | loss: 191.952\n",
            "iter:500 | loss: 143.901\n",
            "iter:600 | loss: 166.123\n",
            "iter:700 | loss: 267.936\n",
            "iter:800 | loss: 201.855\n",
            "iter:900 | loss: 164.007\n",
            "iter:1000 | loss: 220.102\n",
            "iter:1100 | loss: 216.436\n",
            "iter:1200 | loss: 227.965\n",
            "iter:1300 | loss: 192.362\n",
            "iter:1400 | loss: 175.038\n",
            "iter:1500 | loss: 163.007\n",
            "iter:1600 | loss: 174.852\n",
            "iter:1700 | loss: 169.096\n",
            "iter:1800 | loss: 116.844\n",
            "iter:1900 | loss: 160.423\n",
            "iter:2000 | loss: 171.076\n",
            "iter:2100 | loss: 162.807\n",
            "iter:2200 | loss: 191.357\n",
            "iter:2300 | loss: 189.470\n",
            "iter:2400 | loss: 174.276\n",
            "iter:2500 | loss: 155.390\n",
            "iter:2600 | loss: 203.733\n",
            "iter:2700 | loss: 186.464\n",
            "iter:2800 | loss: 193.191\n",
            "iter:2900 | loss: 171.231\n",
            "iter:3000 | loss: 233.452\n",
            "iter:3100 | loss: 184.044\n",
            "iter:3200 | loss: 167.340\n",
            "iter:3300 | loss: 208.363\n",
            "iter:3400 | loss: 171.152\n",
            "iter:3500 | loss: 185.827\n",
            "iter:3600 | loss: 160.913\n",
            "iter:3700 | loss: 185.848\n",
            "iter:3800 | loss: 277.268\n",
            "iter:3900 | loss: 149.001\n",
            "| end of epoch   2 | time: 700.90s | train_loss 180.7124 | valid rse 0.0600 | valid rae 0.0426 | valid corr  0.9272\n",
            "iter:  0 | loss: 179.659\n",
            "iter:100 | loss: 126.994\n",
            "iter:200 | loss: 140.031\n",
            "iter:300 | loss: 128.330\n",
            "iter:400 | loss: 126.141\n",
            "iter:500 | loss: 173.628\n",
            "iter:600 | loss: 158.532\n",
            "iter:700 | loss: 211.693\n",
            "iter:800 | loss: 294.783\n",
            "iter:900 | loss: 166.275\n",
            "iter:1000 | loss: 166.028\n",
            "iter:1100 | loss: 232.419\n",
            "iter:1200 | loss: 222.048\n",
            "iter:1300 | loss: 267.543\n",
            "iter:1400 | loss: 157.585\n",
            "iter:1500 | loss: 149.668\n",
            "iter:1600 | loss: 156.445\n",
            "iter:1700 | loss: 188.624\n",
            "iter:1800 | loss: 138.450\n",
            "iter:1900 | loss: 199.959\n",
            "iter:2000 | loss: 212.418\n",
            "iter:2100 | loss: 156.518\n",
            "iter:2200 | loss: 174.747\n",
            "iter:2300 | loss: 134.932\n",
            "iter:2400 | loss: 169.299\n",
            "iter:2500 | loss: 144.566\n",
            "iter:2600 | loss: 167.058\n",
            "iter:2700 | loss: 176.156\n",
            "iter:2800 | loss: 137.205\n",
            "iter:2900 | loss: 164.753\n",
            "iter:3000 | loss: 126.594\n",
            "iter:3100 | loss: 197.791\n",
            "iter:3200 | loss: 301.398\n",
            "iter:3300 | loss: 186.964\n",
            "iter:3400 | loss: 282.789\n",
            "iter:3500 | loss: 159.440\n",
            "iter:3600 | loss: 127.314\n",
            "iter:3700 | loss: 179.455\n",
            "iter:3800 | loss: 200.456\n",
            "iter:3900 | loss: 139.964\n",
            "| end of epoch   3 | time: 700.83s | train_loss 170.7557 | valid rse 0.0573 | valid rae 0.0416 | valid corr  0.9297\n",
            "final test rse 0.0842 | test rae 0.0489 | test corr 0.9380\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "begin training\n",
            "iter:  0 | loss: 2586.509\n",
            "iter:100 | loss: 283.647\n",
            "iter:200 | loss: 388.206\n",
            "iter:300 | loss: 241.367\n",
            "iter:400 | loss: 330.006\n",
            "iter:500 | loss: 285.758\n",
            "iter:600 | loss: 260.677\n",
            "iter:700 | loss: 146.921\n",
            "iter:800 | loss: 336.960\n",
            "iter:900 | loss: 285.200\n",
            "iter:1000 | loss: 371.451\n",
            "iter:1100 | loss: 208.407\n",
            "iter:1200 | loss: 206.853\n",
            "iter:1300 | loss: 232.838\n",
            "iter:1400 | loss: 253.805\n",
            "iter:1500 | loss: 193.640\n",
            "iter:1600 | loss: 473.596\n",
            "iter:1700 | loss: 171.660\n",
            "iter:1800 | loss: 158.960\n",
            "iter:1900 | loss: 225.857\n",
            "iter:2000 | loss: 154.510\n",
            "iter:2100 | loss: 151.232\n",
            "iter:2200 | loss: 189.282\n",
            "iter:2300 | loss: 166.092\n",
            "iter:2400 | loss: 173.847\n",
            "iter:2500 | loss: 154.050\n",
            "iter:2600 | loss: 328.493\n",
            "iter:2700 | loss: 218.585\n",
            "iter:2800 | loss: 197.745\n",
            "iter:2900 | loss: 177.874\n",
            "iter:3000 | loss: 187.886\n",
            "iter:3100 | loss: 130.706\n",
            "iter:3200 | loss: 137.791\n",
            "iter:3300 | loss: 161.406\n",
            "iter:3400 | loss: 222.476\n",
            "iter:3500 | loss: 158.660\n",
            "iter:3600 | loss: 213.208\n",
            "iter:3700 | loss: 304.846\n",
            "iter:3800 | loss: 111.519\n",
            "iter:3900 | loss: 172.925\n",
            "| end of epoch   1 | time: 700.81s | train_loss 232.9496 | valid rse 0.0570 | valid rae 0.0416 | valid corr  0.9198\n",
            "iter:  0 | loss: 168.769\n",
            "iter:100 | loss: 151.628\n",
            "iter:200 | loss: 183.068\n",
            "iter:300 | loss: 210.784\n",
            "iter:400 | loss: 333.974\n",
            "iter:500 | loss: 177.943\n",
            "iter:600 | loss: 254.181\n",
            "iter:700 | loss: 161.145\n",
            "iter:800 | loss: 190.730\n",
            "iter:900 | loss: 201.497\n",
            "iter:1000 | loss: 180.494\n",
            "iter:1100 | loss: 176.092\n",
            "iter:1200 | loss: 132.626\n",
            "iter:1300 | loss: 142.596\n",
            "iter:1400 | loss: 158.519\n",
            "iter:1500 | loss: 183.254\n",
            "iter:1600 | loss: 147.900\n",
            "iter:1700 | loss: 118.749\n",
            "iter:1800 | loss: 157.708\n",
            "iter:1900 | loss: 201.868\n",
            "iter:2000 | loss: 214.992\n",
            "iter:2100 | loss: 185.163\n",
            "iter:2200 | loss: 128.937\n",
            "iter:2300 | loss: 168.560\n",
            "iter:2400 | loss: 183.728\n",
            "iter:2500 | loss: 109.316\n",
            "iter:2600 | loss: 232.019\n",
            "iter:2700 | loss: 158.069\n",
            "iter:2800 | loss: 210.061\n",
            "iter:2900 | loss: 150.329\n",
            "iter:3000 | loss: 249.855\n",
            "iter:3100 | loss: 164.913\n",
            "iter:3200 | loss: 162.353\n",
            "iter:3300 | loss: 120.836\n",
            "iter:3400 | loss: 184.939\n",
            "iter:3500 | loss: 225.261\n",
            "iter:3600 | loss: 229.621\n",
            "iter:3700 | loss: 152.185\n",
            "iter:3800 | loss: 165.858\n",
            "iter:3900 | loss: 166.233\n",
            "| end of epoch   2 | time: 700.92s | train_loss 177.8686 | valid rse 0.0545 | valid rae 0.0393 | valid corr  0.9270\n",
            "iter:  0 | loss: 132.963\n",
            "iter:100 | loss: 210.251\n",
            "iter:200 | loss: 239.144\n",
            "iter:300 | loss: 146.994\n",
            "iter:400 | loss: 223.688\n",
            "iter:500 | loss: 274.546\n",
            "iter:600 | loss: 164.265\n",
            "iter:700 | loss: 152.649\n",
            "iter:800 | loss: 152.565\n",
            "iter:900 | loss: 279.652\n",
            "iter:1000 | loss: 166.336\n",
            "iter:1100 | loss: 196.812\n",
            "iter:1200 | loss: 205.063\n",
            "iter:1300 | loss: 134.496\n",
            "iter:1400 | loss: 186.436\n",
            "iter:1500 | loss: 126.854\n",
            "iter:1600 | loss: 113.273\n",
            "iter:1700 | loss: 290.157\n",
            "iter:1800 | loss: 161.577\n",
            "iter:1900 | loss: 121.896\n",
            "iter:2000 | loss: 208.759\n",
            "iter:2100 | loss: 259.477\n",
            "iter:2200 | loss: 117.883\n",
            "iter:2300 | loss: 136.622\n",
            "iter:2400 | loss: 189.198\n",
            "iter:2500 | loss: 152.075\n",
            "iter:2600 | loss: 148.085\n",
            "iter:2700 | loss: 153.504\n",
            "iter:2800 | loss: 126.640\n",
            "iter:2900 | loss: 169.519\n",
            "iter:3000 | loss: 147.915\n",
            "iter:3100 | loss: 236.145\n",
            "iter:3200 | loss: 166.275\n",
            "iter:3300 | loss: 168.368\n",
            "iter:3400 | loss: 226.010\n",
            "iter:3500 | loss: 178.163\n",
            "iter:3600 | loss: 159.093\n",
            "iter:3700 | loss: 129.946\n",
            "iter:3800 | loss: 187.594\n",
            "iter:3900 | loss: 175.799\n",
            "| end of epoch   3 | time: 701.50s | train_loss 168.6045 | valid rse 0.0533 | valid rae 0.0382 | valid corr  0.9281\n",
            "final test rse 0.0796 | test rae 0.0453 | test corr 0.9373\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "begin training\n",
            "iter:  0 | loss: 1835.340\n",
            "iter:100 | loss: 451.147\n",
            "iter:200 | loss: 347.065\n",
            "iter:300 | loss: 204.102\n",
            "iter:400 | loss: 282.430\n",
            "iter:500 | loss: 267.144\n",
            "iter:600 | loss: 216.682\n",
            "iter:700 | loss: 307.061\n",
            "iter:800 | loss: 338.183\n",
            "iter:900 | loss: 140.536\n",
            "iter:1000 | loss: 220.947\n",
            "iter:1100 | loss: 291.510\n",
            "iter:1200 | loss: 212.462\n",
            "iter:1300 | loss: 186.690\n",
            "iter:1400 | loss: 204.887\n",
            "iter:1500 | loss: 250.782\n",
            "iter:1600 | loss: 219.257\n",
            "iter:1700 | loss: 182.994\n",
            "iter:1800 | loss: 305.014\n",
            "iter:1900 | loss: 205.523\n",
            "iter:2000 | loss: 209.380\n",
            "iter:2100 | loss: 251.550\n",
            "iter:2200 | loss: 232.101\n",
            "iter:2300 | loss: 184.399\n",
            "iter:2400 | loss: 246.505\n",
            "iter:2500 | loss: 214.242\n",
            "iter:2600 | loss: 140.794\n",
            "iter:2700 | loss: 177.578\n",
            "iter:2800 | loss: 173.777\n",
            "iter:2900 | loss: 247.296\n",
            "iter:3000 | loss: 144.111\n",
            "iter:3100 | loss: 299.980\n",
            "iter:3200 | loss: 213.792\n",
            "iter:3300 | loss: 149.348\n",
            "iter:3400 | loss: 133.064\n",
            "iter:3500 | loss: 174.741\n",
            "iter:3600 | loss: 161.730\n",
            "iter:3700 | loss: 227.388\n",
            "iter:3800 | loss: 122.301\n",
            "iter:3900 | loss: 188.630\n",
            "| end of epoch   1 | time: 700.24s | train_loss 237.6920 | valid rse 0.0579 | valid rae 0.0427 | valid corr  0.9195\n",
            "iter:  0 | loss: 224.250\n",
            "iter:100 | loss: 137.357\n",
            "iter:200 | loss: 182.520\n",
            "iter:300 | loss: 196.956\n",
            "iter:400 | loss: 158.327\n",
            "iter:500 | loss: 169.861\n",
            "iter:600 | loss: 333.909\n",
            "iter:700 | loss: 148.680\n",
            "iter:800 | loss: 279.873\n",
            "iter:900 | loss: 215.706\n",
            "iter:1000 | loss: 164.218\n",
            "iter:1100 | loss: 154.125\n",
            "iter:1200 | loss: 154.589\n",
            "iter:1300 | loss: 204.948\n",
            "iter:1400 | loss: 230.641\n",
            "iter:1500 | loss: 237.332\n",
            "iter:1600 | loss: 180.878\n",
            "iter:1700 | loss: 138.119\n",
            "iter:1800 | loss: 169.794\n",
            "iter:1900 | loss: 227.303\n",
            "iter:2000 | loss: 161.025\n",
            "iter:2100 | loss: 186.639\n",
            "iter:2200 | loss: 159.925\n",
            "iter:2300 | loss: 158.139\n",
            "iter:2400 | loss: 184.300\n",
            "iter:2500 | loss: 182.268\n",
            "iter:2600 | loss: 160.074\n",
            "iter:2700 | loss: 156.711\n",
            "iter:2800 | loss: 133.651\n",
            "iter:2900 | loss: 289.564\n",
            "iter:3000 | loss: 158.037\n",
            "iter:3100 | loss: 176.736\n",
            "iter:3200 | loss: 151.989\n",
            "iter:3300 | loss: 123.485\n",
            "iter:3400 | loss: 225.814\n",
            "iter:3500 | loss: 216.430\n",
            "iter:3600 | loss: 134.539\n",
            "-----------------------------------------------------------------------------------------\n",
            "Exiting from training early\n",
            "final test rse 0.0896 | test rae 0.0507 | test corr 0.9286\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "begin training\n",
            "iter:  0 | loss: 2030.778\n",
            "iter:100 | loss: 424.755\n",
            "iter:200 | loss: 263.381\n",
            "iter:300 | loss: 348.824\n",
            "iter:400 | loss: 378.841\n",
            "iter:500 | loss: 333.300\n",
            "iter:600 | loss: 209.344\n",
            "iter:700 | loss: 475.098\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-adcff2a36157>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"python train_single_step.py --save ./model-electricity-3.pt --data ./data/electricity.txt --num_nodes 321 --batch_size 4 --epochs 3 --horizon 3 --device 'cuda:0'\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'python train_single_step.py --save ./model-electricity-3.pt --data ./data/electricity.txt --num_nodes 321 --batch_size 4 --epochs 3 --horizon 3 --device 'cuda:0'\n' died with <Signals.SIGTERM: 15>."
          ]
        }
      ]
    }
  ]
}