{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "WWVKGT9Vy0wR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG-NfuJiro9z",
        "outputId": "8f2b2143-fca3-484e-a926-f0cac559d999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MTGNN-RCBI'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 146 (delta 77), reused 79 (delta 43), pack-reused 23\u001b[K\n",
            "Receiving objects: 100% (146/146), 94.09 MiB | 35.96 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/crisrm128/MTGNN-RCBI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MTGNN-RCBI/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmmlXLX8r2SO",
        "outputId": "0d6be083-37fd-46a4-fb75-7a05f6a054a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTGNN-RCBI/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip traffic_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_VCFXGJyzks",
        "outputId": "fa6b4c92-07b4-4b41-e240-68aaee818d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  traffic_dataset.zip\n",
            "  inflating: metr-la.h5              \n",
            "  inflating: pems-bay.h5             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip multivariate_timeseries_datasets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uflib9A2ssA",
        "outputId": "81ec5c6e-c4ba-4fc7-f499-c44332150d4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  multivariate_timeseries_datasets.zip\n",
            "  inflating: electricity.txt         \n",
            "  inflating: exchange_rate.txt       \n",
            "  inflating: solar_AL.txt            \n",
            "  inflating: traffic.txt             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {METR-LA,PEMS-BAY}"
      ],
      "metadata": {
        "id": "y-maFJBczH8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux-lLR89zs0m",
        "outputId": "f741d681-89ab-411b-bc1a-5f799332956f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTGNN-RCBI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_training_data.py --output_dir=data/METR-LA --traffic_df_filename=data/metr-la.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3_vkdfQzS_n",
        "outputId": "bef27fb3-3644-49b0-b284-d36a004a6ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data\n",
            "x shape:  (34249, 12, 207, 2) , y shape:  (34249, 12, 207, 2)\n",
            "train x:  (23974, 12, 207, 2) y: (23974, 12, 207, 2)\n",
            "val x:  (3425, 12, 207, 2) y: (3425, 12, 207, 2)\n",
            "test x:  (6850, 12, 207, 2) y: (6850, 12, 207, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "⚠️ It doesn't work well, as I don't know the reason why de \"^C\" appears without pressing any keys.\n",
        "\n",
        "It doesn't matter anyway, because this problem is associated with a traffic dataset, which is irrelevant in this project.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bazLb6R-2Ere"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_training_data.py --output_dir=data/PEMS-BAY --traffic_df_filename=data/pems-bay.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aQpor6hzUpV",
        "outputId": "261bc0cc-3832-462c-9c8e-80fba40e6580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "GR9OVBC3zXuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "python train_single_step.py --save ./model-electricity-3.pt --data ./data/electricity.txt --num_nodes 321 --batch_size 4 --epochs 3 --horizon 3 --device 'cuda:0' --exp_num 3 --sensitivity True --sensitivity_num 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkxCFUDLr5QB",
        "outputId": "9fefd588-52ef-472b-e71d-4f69d90f0417"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified clients:  [173 132 197]\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100, exp_num=3, sensitivity=True, sensitivity_num=3)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "begin training\n",
            "iter:  0 | loss: 1361.991\n",
            "iter:100 | loss: 464.239\n",
            "iter:200 | loss: 224.891\n",
            "iter:300 | loss: 318.059\n",
            "iter:400 | loss: 235.485\n",
            "iter:500 | loss: 248.819\n",
            "iter:600 | loss: 330.443\n",
            "iter:700 | loss: 231.783\n",
            "iter:800 | loss: 281.526\n",
            "iter:900 | loss: 226.306\n",
            "iter:1000 | loss: 157.109\n",
            "iter:1100 | loss: 209.503\n",
            "iter:1200 | loss: 222.254\n",
            "iter:1300 | loss: 216.868\n",
            "iter:1400 | loss: 223.205\n",
            "iter:1500 | loss: 265.961\n",
            "iter:1600 | loss: 181.554\n",
            "iter:1700 | loss: 235.529\n",
            "iter:1800 | loss: 267.145\n",
            "iter:1900 | loss: 201.580\n",
            "iter:2000 | loss: 174.555\n",
            "iter:2100 | loss: 184.447\n",
            "iter:2200 | loss: 172.558\n",
            "iter:2300 | loss: 353.740\n",
            "iter:2400 | loss: 191.782\n",
            "iter:2500 | loss: 190.469\n",
            "iter:2600 | loss: 255.625\n",
            "iter:2700 | loss: 205.965\n",
            "iter:2800 | loss: 319.745\n",
            "iter:2900 | loss: 228.159\n",
            "iter:3000 | loss: 245.251\n",
            "iter:3100 | loss: 189.369\n",
            "iter:3200 | loss: 189.354\n",
            "iter:3300 | loss: 256.280\n",
            "iter:3400 | loss: 159.084\n",
            "iter:3500 | loss: 162.416\n",
            "iter:3600 | loss: 123.980\n",
            "iter:3700 | loss: 280.627\n",
            "iter:3800 | loss: 190.705\n",
            "iter:3900 | loss: 178.136\n",
            "/content/MTGNN-RCBI/train_single_step.py:54: RuntimeWarning: invalid value encountered in divide\n",
            "  correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis=0) / (sigma_p * sigma_g)\n",
            "| end of epoch   1 | time: 706.09s | train_loss 237.3496 | valid rse 0.0571 | valid rae 0.0433 | valid corr  0.9136\n",
            "iter:  0 | loss: 126.950\n",
            "iter:100 | loss: 241.519\n",
            "iter:200 | loss: 133.307\n",
            "iter:300 | loss: 258.158\n",
            "iter:400 | loss: 296.022\n",
            "iter:500 | loss: 209.360\n",
            "iter:600 | loss: 233.962\n",
            "iter:700 | loss: 196.767\n",
            "iter:800 | loss: 195.237\n",
            "iter:900 | loss: 177.305\n",
            "iter:1000 | loss: 191.791\n",
            "iter:1100 | loss: 165.220\n",
            "iter:1200 | loss: 144.315\n",
            "iter:1300 | loss: 142.874\n",
            "iter:1400 | loss: 224.113\n",
            "iter:1500 | loss: 139.798\n",
            "iter:1600 | loss: 225.576\n",
            "iter:1700 | loss: 243.449\n",
            "iter:1800 | loss: 223.433\n",
            "iter:1900 | loss: 140.365\n",
            "iter:2000 | loss: 169.931\n",
            "iter:2100 | loss: 221.653\n",
            "iter:2200 | loss: 159.391\n",
            "iter:2300 | loss: 123.872\n",
            "iter:2400 | loss: 201.509\n",
            "iter:2500 | loss: 171.261\n",
            "iter:2600 | loss: 186.599\n",
            "iter:2700 | loss: 313.408\n",
            "iter:2800 | loss: 196.449\n",
            "iter:2900 | loss: 166.763\n",
            "iter:3000 | loss: 169.444\n",
            "iter:3100 | loss: 172.078\n",
            "iter:3200 | loss: 324.208\n",
            "iter:3300 | loss: 181.608\n",
            "iter:3400 | loss: 128.159\n",
            "iter:3500 | loss: 210.357\n",
            "iter:3600 | loss: 176.851\n",
            "iter:3700 | loss: 223.251\n",
            "iter:3800 | loss: 153.721\n",
            "iter:3900 | loss: 168.166\n",
            "| end of epoch   2 | time: 703.88s | train_loss 181.9507 | valid rse 0.0570 | valid rae 0.0416 | valid corr  0.9170\n",
            "iter:  0 | loss: 136.296\n",
            "iter:100 | loss: 135.211\n",
            "iter:200 | loss: 176.903\n",
            "iter:300 | loss: 128.389\n",
            "iter:400 | loss: 140.732\n",
            "iter:500 | loss: 173.551\n",
            "iter:600 | loss: 165.161\n",
            "iter:700 | loss: 288.573\n",
            "iter:800 | loss: 185.300\n",
            "iter:900 | loss: 204.337\n",
            "iter:1000 | loss: 172.416\n",
            "iter:1100 | loss: 134.300\n",
            "iter:1200 | loss: 232.381\n",
            "iter:1300 | loss: 203.434\n",
            "iter:1400 | loss: 140.956\n",
            "iter:1500 | loss: 173.726\n",
            "iter:1600 | loss: 110.256\n",
            "iter:1700 | loss: 200.998\n",
            "iter:1800 | loss: 171.330\n",
            "iter:1900 | loss: 163.764\n",
            "iter:2000 | loss: 161.390\n",
            "iter:2100 | loss: 189.177\n",
            "iter:2200 | loss: 186.684\n",
            "iter:2300 | loss: 201.234\n",
            "iter:2400 | loss: 272.021\n",
            "iter:2500 | loss: 169.588\n",
            "iter:2600 | loss: 104.174\n",
            "iter:2700 | loss: 178.161\n",
            "iter:2800 | loss: 118.650\n",
            "iter:2900 | loss: 229.251\n",
            "iter:3000 | loss: 121.351\n",
            "iter:3100 | loss: 140.331\n",
            "iter:3200 | loss: 180.597\n",
            "iter:3300 | loss: 219.339\n",
            "iter:3400 | loss: 177.470\n",
            "iter:3500 | loss: 174.417\n",
            "iter:3600 | loss: 167.141\n",
            "iter:3700 | loss: 219.431\n",
            "iter:3800 | loss: 191.444\n",
            "iter:3900 | loss: 151.528\n",
            "| end of epoch   3 | time: 704.42s | train_loss 174.2929 | valid rse 0.0592 | valid rae 0.0427 | valid corr  0.9203\n",
            "Average size for confidence intervals: 3379.1798306369337\n",
            "test rse 0.0845 | test rae 0.0492 | test corr 0.9286\n",
            "final test rse 0.0831 | test rae 0.0483 | test corr 0.9267\n",
            "Modified clients:  [ 77 247 162]\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100, exp_num=3, sensitivity=True, sensitivity_num=3)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "begin training\n",
            "iter:  0 | loss: 1532.622\n",
            "iter:100 | loss: 419.577\n",
            "iter:200 | loss: 346.357\n",
            "iter:300 | loss: 414.297\n",
            "iter:400 | loss: 315.175\n",
            "iter:500 | loss: 221.991\n",
            "iter:600 | loss: 262.121\n",
            "iter:700 | loss: 247.602\n",
            "iter:800 | loss: 265.450\n",
            "iter:900 | loss: 164.121\n",
            "iter:1000 | loss: 220.933\n",
            "iter:1100 | loss: 269.555\n",
            "iter:1200 | loss: 214.591\n",
            "iter:1300 | loss: 222.162\n",
            "iter:1400 | loss: 160.747\n",
            "iter:1500 | loss: 174.599\n",
            "iter:1600 | loss: 214.843\n",
            "iter:1700 | loss: 223.738\n",
            "iter:1800 | loss: 161.979\n",
            "iter:1900 | loss: 223.898\n",
            "iter:2000 | loss: 171.456\n",
            "iter:2100 | loss: 219.849\n",
            "iter:2200 | loss: 146.533\n",
            "iter:2300 | loss: 178.221\n",
            "iter:2400 | loss: 171.899\n",
            "iter:2500 | loss: 217.763\n",
            "iter:2600 | loss: 156.449\n",
            "iter:2700 | loss: 165.177\n",
            "iter:2800 | loss: 236.328\n",
            "iter:2900 | loss: 189.923\n",
            "iter:3000 | loss: 230.894\n",
            "iter:3100 | loss: 178.630\n",
            "iter:3200 | loss: 152.680\n",
            "iter:3300 | loss: 198.920\n",
            "iter:3400 | loss: 157.708\n",
            "iter:3500 | loss: 164.366\n",
            "iter:3600 | loss: 147.737\n",
            "iter:3700 | loss: 141.884\n",
            "iter:3800 | loss: 154.897\n",
            "iter:3900 | loss: 157.484\n",
            "| end of epoch   1 | time: 703.99s | train_loss 237.6015 | valid rse 0.0564 | valid rae 0.0431 | valid corr  0.9150\n",
            "iter:  0 | loss: 218.909\n",
            "iter:100 | loss: 182.815\n",
            "iter:200 | loss: 144.276\n",
            "iter:300 | loss: 175.865\n",
            "iter:400 | loss: 157.165\n",
            "iter:500 | loss: 205.780\n",
            "iter:600 | loss: 306.124\n",
            "iter:700 | loss: 194.971\n",
            "iter:800 | loss: 190.971\n",
            "iter:900 | loss: 164.376\n",
            "iter:1000 | loss: 236.974\n",
            "iter:1100 | loss: 258.002\n",
            "iter:1200 | loss: 164.298\n",
            "iter:1300 | loss: 250.476\n",
            "iter:1400 | loss: 122.915\n",
            "iter:1500 | loss: 134.720\n",
            "iter:1600 | loss: 163.996\n",
            "iter:1700 | loss: 175.627\n",
            "iter:1800 | loss: 198.020\n",
            "iter:1900 | loss: 167.658\n",
            "iter:2000 | loss: 222.694\n",
            "iter:2100 | loss: 217.182\n",
            "iter:2200 | loss: 193.532\n",
            "iter:2300 | loss: 137.639\n",
            "iter:2400 | loss: 222.972\n",
            "iter:2500 | loss: 176.554\n",
            "iter:2600 | loss: 124.404\n",
            "iter:2700 | loss: 203.163\n",
            "iter:2800 | loss: 155.728\n",
            "iter:2900 | loss: 159.468\n",
            "iter:3000 | loss: 161.052\n",
            "iter:3100 | loss: 202.284\n",
            "iter:3200 | loss: 132.067\n",
            "iter:3300 | loss: 166.278\n",
            "iter:3400 | loss: 172.305\n",
            "iter:3500 | loss: 149.220\n",
            "iter:3600 | loss: 182.853\n",
            "iter:3700 | loss: 146.655\n",
            "iter:3800 | loss: 177.075\n",
            "iter:3900 | loss: 143.936\n",
            "| end of epoch   2 | time: 704.52s | train_loss 185.2836 | valid rse 0.0561 | valid rae 0.0413 | valid corr  0.9183\n",
            "iter:  0 | loss: 132.004\n",
            "iter:100 | loss: 169.658\n",
            "iter:200 | loss: 220.907\n",
            "iter:300 | loss: 140.117\n",
            "iter:400 | loss: 166.272\n",
            "iter:500 | loss: 132.041\n",
            "iter:600 | loss: 171.069\n",
            "iter:700 | loss: 155.122\n",
            "iter:800 | loss: 191.337\n",
            "iter:900 | loss: 203.886\n",
            "iter:1000 | loss: 269.159\n",
            "iter:1100 | loss: 188.089\n",
            "iter:1200 | loss: 168.946\n",
            "iter:1300 | loss: 144.637\n",
            "iter:1400 | loss: 197.903\n",
            "iter:1500 | loss: 166.931\n",
            "iter:1600 | loss: 166.624\n",
            "iter:1700 | loss: 124.829\n",
            "iter:1800 | loss: 120.408\n",
            "iter:1900 | loss: 159.913\n",
            "iter:2000 | loss: 155.323\n",
            "iter:2100 | loss: 169.335\n",
            "iter:2200 | loss: 150.302\n",
            "iter:2300 | loss: 163.214\n",
            "iter:2400 | loss: 176.407\n",
            "iter:2500 | loss: 129.389\n",
            "iter:2600 | loss: 194.518\n",
            "iter:2700 | loss: 218.130\n",
            "iter:2800 | loss: 168.124\n",
            "iter:2900 | loss: 207.457\n",
            "iter:3000 | loss: 198.045\n",
            "iter:3100 | loss: 219.023\n",
            "iter:3200 | loss: 159.894\n",
            "iter:3300 | loss: 206.297\n",
            "iter:3400 | loss: 149.781\n",
            "iter:3500 | loss: 128.936\n",
            "iter:3600 | loss: 156.862\n",
            "iter:3700 | loss: 205.056\n",
            "iter:3800 | loss: 162.358\n",
            "iter:3900 | loss: 150.998\n",
            "| end of epoch   3 | time: 704.96s | train_loss 176.5154 | valid rse 0.0550 | valid rae 0.0408 | valid corr  0.9208\n",
            "Average size for confidence intervals: 3327.753490789657\n",
            "test rse 0.0799 | test rae 0.0473 | test corr 0.9305\n",
            "final test rse 0.0799 | test rae 0.0473 | test corr 0.9306\n",
            "Modified clients:  [235  77 167]\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100, exp_num=3, sensitivity=True, sensitivity_num=3)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "begin training\n",
            "iter:  0 | loss: 3895.182\n",
            "iter:100 | loss: 409.832\n",
            "iter:200 | loss: 311.014\n",
            "iter:300 | loss: 375.907\n",
            "iter:400 | loss: 418.399\n",
            "iter:500 | loss: 546.428\n",
            "iter:600 | loss: 338.421\n",
            "iter:700 | loss: 316.217\n",
            "iter:800 | loss: 229.035\n",
            "iter:900 | loss: 211.283\n",
            "iter:1000 | loss: 333.598\n",
            "iter:1100 | loss: 218.351\n",
            "iter:1200 | loss: 224.214\n",
            "iter:1300 | loss: 256.137\n",
            "iter:1400 | loss: 232.732\n",
            "iter:1500 | loss: 189.848\n",
            "iter:1600 | loss: 191.792\n",
            "iter:1700 | loss: 236.512\n",
            "iter:1800 | loss: 193.348\n",
            "iter:1900 | loss: 159.679\n",
            "iter:2000 | loss: 227.974\n",
            "iter:2100 | loss: 272.874\n",
            "iter:2200 | loss: 172.933\n",
            "iter:2300 | loss: 213.335\n",
            "iter:2400 | loss: 196.011\n",
            "iter:2500 | loss: 203.314\n",
            "iter:2600 | loss: 272.413\n",
            "iter:2700 | loss: 194.249\n",
            "iter:2800 | loss: 297.975\n",
            "iter:2900 | loss: 295.975\n",
            "iter:3000 | loss: 208.144\n",
            "iter:3100 | loss: 232.452\n",
            "iter:3200 | loss: 193.041\n",
            "iter:3300 | loss: 232.493\n",
            "iter:3400 | loss: 197.226\n",
            "iter:3500 | loss: 224.694\n",
            "iter:3600 | loss: 325.373\n",
            "iter:3700 | loss: 206.424\n",
            "iter:3800 | loss: 215.899\n",
            "iter:3900 | loss: 184.979\n",
            "| end of epoch   1 | time: 704.82s | train_loss 265.1989 | valid rse 0.0770 | valid rae 0.0544 | valid corr  0.9169\n",
            "iter:  0 | loss: 199.553\n",
            "iter:100 | loss: 398.445\n",
            "iter:200 | loss: 202.187\n",
            "iter:300 | loss: 157.182\n",
            "iter:400 | loss: 180.166\n",
            "iter:500 | loss: 200.054\n",
            "iter:600 | loss: 198.530\n",
            "iter:700 | loss: 209.331\n",
            "iter:800 | loss: 220.374\n",
            "iter:900 | loss: 258.700\n",
            "iter:1000 | loss: 177.193\n",
            "iter:1100 | loss: 194.234\n",
            "iter:1200 | loss: 190.189\n",
            "iter:1300 | loss: 261.102\n",
            "iter:1400 | loss: 215.876\n",
            "iter:1500 | loss: 242.618\n",
            "iter:1600 | loss: 259.497\n",
            "iter:1700 | loss: 188.908\n",
            "iter:1800 | loss: 238.633\n",
            "iter:1900 | loss: 265.420\n",
            "iter:2000 | loss: 216.445\n",
            "iter:2100 | loss: 235.107\n",
            "iter:2200 | loss: 201.058\n",
            "iter:2300 | loss: 279.220\n",
            "iter:2400 | loss: 170.270\n",
            "iter:2500 | loss: 240.921\n",
            "iter:2600 | loss: 186.589\n",
            "iter:2700 | loss: 272.559\n",
            "iter:2800 | loss: 218.034\n",
            "iter:2900 | loss: 179.130\n",
            "iter:3000 | loss: 225.301\n",
            "iter:3100 | loss: 174.678\n",
            "iter:3200 | loss: 281.423\n",
            "iter:3300 | loss: 193.641\n",
            "iter:3400 | loss: 224.099\n",
            "iter:3500 | loss: 137.009\n",
            "iter:3600 | loss: 244.908\n",
            "iter:3700 | loss: 196.118\n",
            "iter:3800 | loss: 182.450\n",
            "iter:3900 | loss: 167.261\n",
            "| end of epoch   2 | time: 703.68s | train_loss 215.2160 | valid rse 0.0763 | valid rae 0.0542 | valid corr  0.9189\n",
            "iter:  0 | loss: 196.432\n",
            "iter:100 | loss: 241.682\n",
            "iter:200 | loss: 164.599\n",
            "iter:300 | loss: 219.485\n",
            "iter:400 | loss: 168.306\n",
            "iter:500 | loss: 209.390\n",
            "iter:600 | loss: 182.745\n",
            "iter:700 | loss: 267.547\n",
            "iter:800 | loss: 192.887\n",
            "iter:900 | loss: 177.489\n",
            "iter:1000 | loss: 216.423\n",
            "iter:1100 | loss: 171.245\n",
            "iter:1200 | loss: 204.459\n",
            "iter:1300 | loss: 189.516\n",
            "iter:1400 | loss: 237.734\n",
            "iter:1500 | loss: 214.149\n",
            "iter:1600 | loss: 180.805\n",
            "iter:1700 | loss: 183.311\n",
            "iter:1800 | loss: 220.015\n",
            "iter:1900 | loss: 187.419\n",
            "iter:2000 | loss: 226.727\n",
            "iter:2100 | loss: 220.964\n",
            "iter:2200 | loss: 223.557\n",
            "iter:2300 | loss: 227.038\n",
            "iter:2400 | loss: 199.949\n",
            "iter:2500 | loss: 461.214\n",
            "iter:2600 | loss: 222.208\n",
            "iter:2700 | loss: 236.560\n",
            "iter:2800 | loss: 171.709\n",
            "iter:2900 | loss: 260.319\n",
            "iter:3000 | loss: 148.352\n",
            "iter:3100 | loss: 270.645\n",
            "iter:3200 | loss: 265.739\n",
            "iter:3300 | loss: 204.064\n",
            "iter:3400 | loss: 221.147\n",
            "iter:3500 | loss: 158.364\n",
            "iter:3600 | loss: 148.116\n",
            "iter:3700 | loss: 219.756\n",
            "iter:3800 | loss: 215.676\n",
            "iter:3900 | loss: 167.236\n",
            "| end of epoch   3 | time: 703.57s | train_loss 207.2794 | valid rse 0.0756 | valid rae 0.0513 | valid corr  0.9202\n",
            "Average size for confidence intervals: 3411.886109729422\n",
            "test rse 0.0946 | test rae 0.0582 | test corr 0.9286\n",
            "final test rse 0.0946 | test rae 0.0582 | test corr 0.9286\n",
            "\n",
            "\n",
            "\n",
            "3 runs average\n",
            "\n",
            "\n",
            "\n",
            "valid\trse\trae\tcorr\n",
            "mean\t0.0625\t0.0446\t0.9194\n",
            "std\t0.0092\t0.0048\t0.0017\n",
            "\n",
            "\n",
            "\n",
            "test\trse\trae\tcorr\n",
            "mean\t0.0859\t0.0513\t0.9286\n",
            "std\t0.0063\t0.0049\t0.0016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}