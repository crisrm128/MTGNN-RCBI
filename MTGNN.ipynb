{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "WWVKGT9Vy0wR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG-NfuJiro9z",
        "outputId": "cfc23c0e-f327-4353-ffcb-bc7dbe1bfad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MTGNN-RCBI'...\n",
            "remote: Enumerating objects: 229, done.\u001b[K\n",
            "remote: Counting objects: 100% (206/206), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 229 (delta 122), reused 151 (delta 88), pack-reused 23\u001b[K\n",
            "Receiving objects: 100% (229/229), 95.48 MiB | 35.09 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/crisrm128/MTGNN-RCBI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MTGNN-RCBI/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmmlXLX8r2SO",
        "outputId": "57646a44-7fb2-4fe0-f678-4e1f68ae1f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTGNN-RCBI/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip multivariate_timeseries_datasets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uflib9A2ssA",
        "outputId": "a0ab62b8-93a2-4307-fd48-e37e73e3da18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  multivariate_timeseries_datasets.zip\n",
            "  inflating: electricity.txt         \n",
            "  inflating: exchange_rate.txt       \n",
            "  inflating: solar_AL.txt            \n",
            "  inflating: traffic.txt             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux-lLR89zs0m",
        "outputId": "69bbaa6c-1447-47ca-de06-b465c8470a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTGNN-RCBI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "GR9OVBC3zXuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "python train_single_step.py --save ./model-electricity-3.pt --data ./data/electricity.txt --num_nodes 321 --batch_size 4 --epochs 3 --horizon 3 --device 'cuda:0' --exp_num 3 --sensitivity True --sensitivity_num 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkxCFUDLr5QB",
        "outputId": "436450bd-c07c-4bdd-d804-93fe8afe2def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified clients:  [77, 167, 235]\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100, exp_num=3, sensitivity=True, sensitivity_num=3)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "begin training\n",
            "iter:  0 | loss: 3568.402\n",
            "iter:100 | loss: 370.901\n",
            "iter:200 | loss: 440.390\n",
            "iter:300 | loss: 244.808\n",
            "iter:400 | loss: 403.148\n",
            "iter:500 | loss: 385.115\n",
            "iter:600 | loss: 336.485\n",
            "iter:700 | loss: 252.075\n",
            "iter:800 | loss: 234.103\n",
            "iter:900 | loss: 331.716\n",
            "iter:1000 | loss: 219.136\n",
            "iter:1100 | loss: 241.475\n",
            "iter:1200 | loss: 284.863\n",
            "iter:1300 | loss: 262.489\n",
            "iter:1400 | loss: 239.019\n",
            "iter:1500 | loss: 247.004\n",
            "iter:1600 | loss: 329.638\n",
            "iter:1700 | loss: 297.970\n",
            "iter:1800 | loss: 227.633\n",
            "iter:1900 | loss: 395.197\n",
            "iter:2000 | loss: 232.419\n",
            "iter:2100 | loss: 188.445\n",
            "iter:2200 | loss: 196.484\n",
            "iter:2300 | loss: 264.274\n",
            "iter:2400 | loss: 191.232\n",
            "iter:2500 | loss: 196.196\n",
            "iter:2600 | loss: 255.010\n",
            "iter:2700 | loss: 198.108\n",
            "iter:2800 | loss: 227.250\n",
            "iter:2900 | loss: 249.631\n",
            "iter:3000 | loss: 244.620\n",
            "iter:3100 | loss: 268.560\n",
            "iter:3200 | loss: 228.681\n",
            "iter:3300 | loss: 278.877\n",
            "iter:3400 | loss: 243.120\n",
            "iter:3500 | loss: 237.123\n",
            "iter:3600 | loss: 224.674\n",
            "iter:3700 | loss: 182.123\n",
            "iter:3800 | loss: 298.897\n",
            "iter:3900 | loss: 217.642\n",
            "/content/MTGNN-RCBI/train_single_step.py:54: RuntimeWarning: invalid value encountered in divide\n",
            "  correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis=0) / (sigma_p * sigma_g)\n",
            "| end of epoch   1 | time: 687.30s | train_loss 283.6761 | valid rse 0.0787 | valid rae 0.0555 | valid corr  0.9113\n",
            "iter:  0 | loss: 248.894\n",
            "iter:100 | loss: 311.871\n",
            "iter:200 | loss: 243.165\n",
            "iter:300 | loss: 164.892\n",
            "iter:400 | loss: 183.929\n",
            "iter:500 | loss: 202.694\n",
            "iter:600 | loss: 215.100\n",
            "iter:700 | loss: 182.233\n",
            "iter:800 | loss: 197.268\n",
            "iter:900 | loss: 218.518\n",
            "iter:1000 | loss: 214.150\n",
            "iter:1100 | loss: 185.844\n",
            "iter:1200 | loss: 220.782\n",
            "iter:1300 | loss: 209.771\n",
            "iter:1400 | loss: 192.320\n",
            "iter:1500 | loss: 239.318\n",
            "iter:1600 | loss: 200.020\n",
            "iter:1700 | loss: 239.458\n",
            "iter:1800 | loss: 242.944\n",
            "iter:1900 | loss: 170.802\n",
            "iter:2000 | loss: 218.456\n",
            "iter:2100 | loss: 240.997\n",
            "iter:2200 | loss: 145.747\n",
            "iter:2300 | loss: 356.311\n",
            "iter:2400 | loss: 194.678\n",
            "iter:2500 | loss: 202.507\n",
            "iter:2600 | loss: 224.322\n",
            "iter:2700 | loss: 256.258\n",
            "iter:2800 | loss: 195.174\n",
            "iter:2900 | loss: 226.889\n",
            "iter:3000 | loss: 216.774\n",
            "iter:3100 | loss: 261.508\n",
            "iter:3200 | loss: 175.827\n",
            "iter:3300 | loss: 173.997\n",
            "iter:3400 | loss: 365.558\n",
            "iter:3500 | loss: 153.618\n",
            "iter:3600 | loss: 213.320\n",
            "iter:3700 | loss: 232.782\n",
            "iter:3800 | loss: 175.060\n",
            "iter:3900 | loss: 170.876\n",
            "| end of epoch   2 | time: 686.75s | train_loss 220.5513 | valid rse 0.0752 | valid rae 0.0517 | valid corr  0.9166\n",
            "iter:  0 | loss: 246.666\n",
            "iter:100 | loss: 165.237\n",
            "iter:200 | loss: 210.499\n",
            "iter:300 | loss: 209.770\n",
            "iter:400 | loss: 250.403\n",
            "iter:500 | loss: 225.555\n",
            "iter:600 | loss: 266.778\n",
            "iter:700 | loss: 197.500\n",
            "iter:800 | loss: 153.009\n",
            "iter:900 | loss: 174.647\n",
            "iter:1000 | loss: 215.316\n",
            "iter:1100 | loss: 222.614\n",
            "iter:1200 | loss: 239.693\n",
            "iter:1300 | loss: 172.890\n",
            "iter:1400 | loss: 206.742\n",
            "iter:1500 | loss: 163.777\n",
            "iter:1600 | loss: 147.087\n",
            "iter:1700 | loss: 195.407\n",
            "iter:1800 | loss: 178.412\n",
            "iter:1900 | loss: 143.708\n",
            "iter:2000 | loss: 166.956\n",
            "iter:2100 | loss: 304.558\n",
            "iter:2200 | loss: 157.061\n",
            "iter:2300 | loss: 201.419\n",
            "iter:2400 | loss: 195.907\n",
            "iter:2500 | loss: 216.404\n",
            "iter:2600 | loss: 181.053\n",
            "iter:2700 | loss: 227.639\n",
            "iter:2800 | loss: 195.462\n",
            "iter:2900 | loss: 236.892\n",
            "iter:3000 | loss: 235.821\n",
            "iter:3100 | loss: 202.128\n",
            "iter:3200 | loss: 174.958\n",
            "iter:3300 | loss: 232.055\n",
            "iter:3400 | loss: 271.365\n",
            "iter:3500 | loss: 210.256\n",
            "iter:3600 | loss: 163.725\n",
            "iter:3700 | loss: 161.900\n",
            "iter:3800 | loss: 195.766\n",
            "iter:3900 | loss: 153.188\n",
            "| end of epoch   3 | time: 685.11s | train_loss 210.2735 | valid rse 0.0747 | valid rae 0.0505 | valid corr  0.9195\n",
            "Average size for confidence intervals: 3342.706923182044\n",
            "test rse 0.0971 | test rae 0.0580 | test corr 0.9280\n",
            "final test rse 0.0972 | test rae 0.0580 | test corr 0.9280\n",
            "Modified clients:  [77, 167, 235]\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100, exp_num=3, sensitivity=True, sensitivity_num=3)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "begin training\n",
            "iter:  0 | loss: 2487.763\n",
            "iter:100 | loss: 658.963\n",
            "iter:200 | loss: 539.024\n",
            "iter:300 | loss: 416.066\n",
            "iter:400 | loss: 456.088\n",
            "iter:500 | loss: 374.834\n",
            "iter:600 | loss: 278.381\n",
            "iter:700 | loss: 334.199\n",
            "iter:800 | loss: 293.675\n",
            "iter:900 | loss: 295.439\n",
            "iter:1000 | loss: 222.213\n",
            "iter:1100 | loss: 275.613\n",
            "iter:1200 | loss: 245.543\n",
            "iter:1300 | loss: 287.390\n",
            "iter:1400 | loss: 396.834\n",
            "iter:1500 | loss: 286.088\n",
            "iter:1600 | loss: 267.237\n",
            "iter:1700 | loss: 180.182\n",
            "iter:1800 | loss: 219.369\n",
            "iter:1900 | loss: 237.638\n",
            "iter:2000 | loss: 215.503\n",
            "iter:2100 | loss: 257.527\n",
            "iter:2200 | loss: 188.606\n",
            "iter:2300 | loss: 263.980\n",
            "iter:2400 | loss: 215.058\n",
            "iter:2500 | loss: 574.059\n",
            "iter:2600 | loss: 254.524\n",
            "iter:2700 | loss: 215.614\n",
            "iter:2800 | loss: 176.752\n",
            "iter:2900 | loss: 250.818\n",
            "iter:3000 | loss: 193.215\n",
            "iter:3100 | loss: 223.378\n",
            "iter:3200 | loss: 182.762\n",
            "iter:3300 | loss: 245.729\n",
            "iter:3400 | loss: 215.790\n",
            "iter:3500 | loss: 351.581\n",
            "iter:3600 | loss: 218.030\n",
            "iter:3700 | loss: 267.643\n",
            "iter:3800 | loss: 191.764\n",
            "iter:3900 | loss: 234.631\n",
            "| end of epoch   1 | time: 686.18s | train_loss 280.3103 | valid rse 0.0777 | valid rae 0.0544 | valid corr  0.9107\n",
            "iter:  0 | loss: 192.894\n",
            "iter:100 | loss: 209.575\n",
            "iter:200 | loss: 317.425\n",
            "iter:300 | loss: 222.437\n",
            "iter:400 | loss: 200.497\n",
            "iter:500 | loss: 201.633\n",
            "iter:600 | loss: 167.570\n",
            "iter:700 | loss: 197.147\n",
            "iter:800 | loss: 190.231\n",
            "iter:900 | loss: 203.498\n",
            "iter:1000 | loss: 233.751\n",
            "iter:1100 | loss: 223.855\n",
            "iter:1200 | loss: 186.015\n",
            "iter:1300 | loss: 183.808\n",
            "iter:1400 | loss: 244.345\n",
            "iter:1500 | loss: 252.649\n",
            "iter:1600 | loss: 297.360\n",
            "iter:1700 | loss: 275.971\n",
            "iter:1800 | loss: 228.214\n",
            "iter:1900 | loss: 259.070\n",
            "iter:2000 | loss: 194.173\n",
            "iter:2100 | loss: 163.380\n",
            "iter:2200 | loss: 149.561\n",
            "iter:2300 | loss: 216.408\n",
            "iter:2400 | loss: 210.844\n",
            "iter:2500 | loss: 204.567\n",
            "iter:2600 | loss: 283.223\n",
            "iter:2700 | loss: 250.216\n",
            "iter:2800 | loss: 230.596\n",
            "iter:2900 | loss: 210.489\n",
            "iter:3000 | loss: 280.244\n",
            "iter:3100 | loss: 176.830\n",
            "iter:3200 | loss: 193.352\n",
            "iter:3300 | loss: 202.966\n",
            "iter:3400 | loss: 167.940\n",
            "iter:3500 | loss: 179.653\n",
            "iter:3600 | loss: 242.839\n",
            "iter:3700 | loss: 178.143\n",
            "iter:3800 | loss: 275.445\n",
            "iter:3900 | loss: 169.010\n",
            "| end of epoch   2 | time: 685.73s | train_loss 221.4663 | valid rse 0.0764 | valid rae 0.0526 | valid corr  0.9169\n",
            "iter:  0 | loss: 274.825\n",
            "iter:100 | loss: 169.629\n",
            "iter:200 | loss: 195.432\n",
            "iter:300 | loss: 182.946\n",
            "iter:400 | loss: 173.787\n",
            "iter:500 | loss: 204.766\n",
            "iter:600 | loss: 368.488\n",
            "iter:700 | loss: 231.879\n",
            "iter:800 | loss: 236.756\n",
            "iter:900 | loss: 160.962\n",
            "iter:1000 | loss: 190.203\n",
            "iter:1100 | loss: 210.616\n",
            "iter:1200 | loss: 159.831\n",
            "iter:1300 | loss: 199.358\n",
            "iter:1400 | loss: 165.441\n",
            "iter:1500 | loss: 206.196\n",
            "iter:1600 | loss: 249.229\n",
            "iter:1700 | loss: 172.095\n",
            "iter:1800 | loss: 219.692\n",
            "iter:1900 | loss: 175.879\n",
            "iter:2000 | loss: 148.466\n",
            "iter:2100 | loss: 226.989\n",
            "iter:2200 | loss: 220.016\n",
            "iter:2300 | loss: 507.599\n",
            "iter:2400 | loss: 215.094\n",
            "iter:2500 | loss: 191.058\n",
            "iter:2600 | loss: 244.607\n",
            "iter:2700 | loss: 279.348\n",
            "iter:2800 | loss: 183.557\n",
            "iter:2900 | loss: 169.652\n",
            "iter:3000 | loss: 317.246\n",
            "iter:3100 | loss: 170.032\n",
            "iter:3200 | loss: 185.802\n",
            "iter:3300 | loss: 213.717\n",
            "iter:3400 | loss: 234.900\n",
            "iter:3500 | loss: 191.658\n",
            "iter:3600 | loss: 191.436\n",
            "iter:3700 | loss: 205.907\n",
            "iter:3800 | loss: 239.022\n",
            "iter:3900 | loss: 224.031\n",
            "| end of epoch   3 | time: 685.49s | train_loss 212.0070 | valid rse 0.0758 | valid rae 0.0511 | valid corr  0.9201\n",
            "Average size for confidence intervals: 3275.1981069577446\n",
            "test rse 0.0977 | test rae 0.0585 | test corr 0.9290\n",
            "final test rse 0.0978 | test rae 0.0585 | test corr 0.9290\n",
            "Modified clients:  [77, 167, 235]\n",
            "Namespace(data='./data/electricity.txt', log_interval=2000, save='./model-electricity-3.pt', optim='adam', L1Loss=True, normalize=2, device='cuda:0', gcn_true=True, buildA_true=True, gcn_depth=2, num_nodes=321, dropout=0.3, subgraph_size=20, node_dim=40, dilation_exponential=2, conv_channels=16, residual_channels=16, skip_channels=32, end_channels=64, in_dim=1, seq_in_len=168, seq_out_len=1, horizon=3, layers=5, batch_size=4, lr=0.0001, weight_decay=1e-05, clip=5, propalpha=0.05, tanhalpha=3, epochs=3, num_split=1, step_size=100, exp_num=3, sensitivity=True, sensitivity_num=3)\n",
            "The recpetive field size is 187\n",
            "Number of model parameters is 362385\n",
            "begin training\n",
            "iter:  0 | loss: 1310.513\n",
            "iter:100 | loss: 444.903\n",
            "iter:200 | loss: 288.045\n",
            "iter:300 | loss: 317.077\n",
            "iter:400 | loss: 274.465\n",
            "iter:500 | loss: 303.378\n",
            "iter:600 | loss: 321.243\n",
            "iter:700 | loss: 237.986\n",
            "iter:800 | loss: 413.130\n",
            "iter:900 | loss: 253.315\n",
            "iter:1000 | loss: 231.420\n",
            "iter:1100 | loss: 216.718\n",
            "iter:1200 | loss: 240.221\n",
            "iter:1300 | loss: 348.336\n",
            "iter:1400 | loss: 196.705\n",
            "iter:1500 | loss: 492.184\n",
            "iter:1600 | loss: 261.806\n",
            "iter:1700 | loss: 212.704\n",
            "iter:1800 | loss: 379.575\n",
            "iter:1900 | loss: 213.987\n",
            "iter:2000 | loss: 227.995\n",
            "iter:2100 | loss: 294.623\n",
            "iter:2200 | loss: 336.607\n",
            "iter:2300 | loss: 201.030\n",
            "iter:2400 | loss: 243.107\n",
            "iter:2500 | loss: 272.530\n",
            "iter:2600 | loss: 221.943\n",
            "iter:2700 | loss: 135.637\n",
            "iter:2800 | loss: 199.811\n",
            "iter:2900 | loss: 321.125\n",
            "iter:3000 | loss: 209.441\n",
            "iter:3100 | loss: 270.020\n",
            "iter:3200 | loss: 167.331\n",
            "iter:3300 | loss: 267.591\n",
            "iter:3400 | loss: 173.708\n",
            "iter:3500 | loss: 172.954\n",
            "iter:3600 | loss: 143.774\n",
            "iter:3700 | loss: 260.376\n",
            "iter:3800 | loss: 278.993\n",
            "iter:3900 | loss: 387.201\n",
            "| end of epoch   1 | time: 687.64s | train_loss 258.1824 | valid rse 0.0759 | valid rae 0.0530 | valid corr  0.9150\n",
            "iter:  0 | loss: 240.359\n",
            "iter:100 | loss: 191.841\n",
            "iter:200 | loss: 163.640\n",
            "iter:300 | loss: 245.706\n",
            "iter:400 | loss: 228.304\n",
            "iter:500 | loss: 205.722\n",
            "iter:600 | loss: 262.892\n",
            "iter:700 | loss: 162.266\n",
            "iter:800 | loss: 257.710\n",
            "iter:900 | loss: 191.296\n",
            "iter:1000 | loss: 185.227\n",
            "iter:1100 | loss: 182.369\n",
            "iter:1200 | loss: 214.433\n",
            "iter:1300 | loss: 175.896\n",
            "iter:1400 | loss: 285.472\n",
            "iter:1500 | loss: 259.202\n",
            "iter:1600 | loss: 219.533\n",
            "iter:1700 | loss: 209.614\n",
            "iter:1800 | loss: 212.531\n",
            "iter:1900 | loss: 232.860\n",
            "iter:2000 | loss: 239.570\n",
            "iter:2100 | loss: 235.717\n",
            "iter:2200 | loss: 207.964\n",
            "iter:2300 | loss: 193.910\n",
            "iter:2400 | loss: 180.235\n",
            "iter:2500 | loss: 267.354\n",
            "iter:2600 | loss: 215.785\n",
            "iter:2700 | loss: 270.614\n",
            "iter:2800 | loss: 190.299\n",
            "iter:2900 | loss: 203.245\n",
            "iter:3000 | loss: 212.507\n",
            "iter:3100 | loss: 227.018\n",
            "iter:3200 | loss: 186.543\n",
            "iter:3300 | loss: 252.654\n",
            "iter:3400 | loss: 233.674\n",
            "iter:3500 | loss: 151.812\n",
            "iter:3600 | loss: 208.152\n",
            "iter:3700 | loss: 217.167\n",
            "iter:3800 | loss: 234.454\n",
            "iter:3900 | loss: 183.235\n",
            "| end of epoch   2 | time: 690.46s | train_loss 216.3047 | valid rse 0.0756 | valid rae 0.0522 | valid corr  0.9169\n",
            "iter:  0 | loss: 170.648\n",
            "iter:100 | loss: 151.808\n",
            "iter:200 | loss: 164.696\n",
            "iter:300 | loss: 153.635\n",
            "iter:400 | loss: 183.469\n",
            "iter:500 | loss: 185.062\n",
            "iter:600 | loss: 226.235\n",
            "iter:700 | loss: 217.947\n",
            "iter:800 | loss: 160.195\n",
            "iter:900 | loss: 164.398\n",
            "iter:1000 | loss: 228.207\n",
            "iter:1100 | loss: 218.065\n",
            "iter:1200 | loss: 253.522\n",
            "iter:1300 | loss: 257.365\n",
            "iter:1400 | loss: 233.329\n",
            "iter:1500 | loss: 228.848\n",
            "iter:1600 | loss: 215.252\n",
            "iter:1700 | loss: 202.321\n",
            "iter:1800 | loss: 240.570\n",
            "iter:1900 | loss: 137.258\n",
            "iter:2000 | loss: 150.256\n",
            "iter:2100 | loss: 190.020\n",
            "iter:2200 | loss: 171.456\n",
            "iter:2300 | loss: 259.955\n",
            "iter:2400 | loss: 202.956\n",
            "iter:2500 | loss: 221.469\n",
            "iter:2600 | loss: 197.096\n",
            "iter:2700 | loss: 232.525\n",
            "iter:2800 | loss: 142.534\n",
            "iter:2900 | loss: 261.553\n",
            "iter:3000 | loss: 341.971\n",
            "iter:3100 | loss: 197.068\n",
            "iter:3200 | loss: 191.329\n",
            "iter:3300 | loss: 210.097\n",
            "iter:3400 | loss: 279.398\n",
            "iter:3500 | loss: 200.741\n",
            "iter:3600 | loss: 196.560\n",
            "iter:3700 | loss: 192.267\n",
            "iter:3800 | loss: 209.862\n",
            "iter:3900 | loss: 278.369\n",
            "| end of epoch   3 | time: 690.40s | train_loss 209.7914 | valid rse 0.0752 | valid rae 0.0514 | valid corr  0.9183\n",
            "Average size for confidence intervals: 3392.9859811073848\n",
            "test rse 0.0968 | test rae 0.0588 | test corr 0.9270\n",
            "final test rse 0.0967 | test rae 0.0588 | test corr 0.9270\n",
            "\n",
            "\n",
            "\n",
            "3 runs average\n",
            "\n",
            "\n",
            "\n",
            "valid\trse\trae\tcorr\n",
            "mean\t0.0752\t0.0510\t0.9193\n",
            "std\t0.0004\t0.0004\t0.0007\n",
            "\n",
            "\n",
            "\n",
            "test\trse\trae\tcorr\n",
            "mean\t0.0972\t0.0585\t0.9280\n",
            "std\t0.0004\t0.0003\t0.0008\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}